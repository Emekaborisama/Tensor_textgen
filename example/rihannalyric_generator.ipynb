{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "cell_id": "00000-efdb0d9d-9bd6-4351-a986-46dfe5536829",
        "deepnote_cell_type": "code"
      },
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
      "outputs": [
        {
          "output_type": "stream",
          "text": "/kaggle/input/poetry/Kanye_West.txt\n/kaggle/input/poetry/johnny-cash.txt\n/kaggle/input/poetry/kanye-west.txt\n/kaggle/input/poetry/bruno-mars.txt\n/kaggle/input/poetry/dickinson.txt\n/kaggle/input/poetry/amy-winehouse.txt\n/kaggle/input/poetry/blink-182.txt\n/kaggle/input/poetry/paul-simon.txt\n/kaggle/input/poetry/patti-smith.txt\n/kaggle/input/poetry/bieber.txt\n/kaggle/input/poetry/disney.txt\n/kaggle/input/poetry/jimi-hendrix.txt\n/kaggle/input/poetry/lin-manuel-miranda.txt\n/kaggle/input/poetry/adele.txt\n/kaggle/input/poetry/dj-khaled.txt\n/kaggle/input/poetry/beatles.txt\n/kaggle/input/poetry/r-kelly.txt\n/kaggle/input/poetry/lady-gaga.txt\n/kaggle/input/poetry/radiohead.txt\n/kaggle/input/poetry/britney-spears.txt\n/kaggle/input/poetry/alicia-keys.txt\n/kaggle/input/poetry/rihanna.txt\n/kaggle/input/poetry/joni-mitchell.txt\n/kaggle/input/poetry/dolly-parton.txt\n/kaggle/input/poetry/drake.txt\n/kaggle/input/poetry/Lil_Wayne.txt\n/kaggle/input/poetry/notorious_big.txt\n/kaggle/input/poetry/eminem.txt\n/kaggle/input/poetry/janisjoplin.txt\n/kaggle/input/poetry/prince.txt\n/kaggle/input/poetry/bruce-springsteen.txt\n/kaggle/input/poetry/bob-dylan.txt\n/kaggle/input/poetry/notorious-big.txt\n/kaggle/input/poetry/lil-wayne.txt\n/kaggle/input/poetry/dr-seuss.txt\n/kaggle/input/poetry/nicki-minaj.txt\n/kaggle/input/poetry/bob-marley.txt\n/kaggle/input/poetry/al-green.txt\n/kaggle/input/poetry/nickelback.txt\n/kaggle/input/poetry/michael-jackson.txt\n/kaggle/input/poetry/lorde.txt\n/kaggle/input/poetry/kanye.txt\n/kaggle/input/poetry/leonard-cohen.txt\n/kaggle/input/poetry/ludacris.txt\n/kaggle/input/poetry/bjork.txt\n/kaggle/input/poetry/nursery_rhymes.txt\n/kaggle/input/poetry/nirvana.txt\n/kaggle/input/poetry/cake.txt\n/kaggle/input/poetry/missy-elliott.txt\n",
          "name": "stdout"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00001-dddbde68-5180-4af4-9d2b-a161d4523ec2",
        "deepnote_cell_type": "code"
      },
      "source": "data = open('/kaggle/input/poetry/rihanna.txt').read()\n\n\ncorpus = data.lower().split(\"\\n\")\ncorpus",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "['now greetings to the world! standing at this liquor store,',\n 'whiskey coming through my pores,',\n 'feeling like i run this whole block.',\n 'lotto tickets cheap beer',\n \"that's why you can catch me here,\",\n \"tryna scratch my way up to the top. 'cause my job got me going nowhere,\",\n \"so i ain't got a thing to lose.\",\n \"take me to a place where i don't care,\",\n \"this is me and my liquor store blues. i'll take one shot for my pain,\",\n 'one drag for my sorrow.',\n 'get messed up today,',\n \"i'll be ok tomorrow.\",\n 'one shot for my pain,',\n 'one drag for my sorrow.',\n 'get messed up today,',\n \"i'll be ok tomorrow. me and my guitar tonight,\",\n 'singing to the city lights,',\n 'tryna live on more than what i got.',\n \"'cause '68 cents ain't gonna pay the rent,\",\n \"so i'll be out here 'til they call the cops. 'cause my job got me going nowhere,\",\n \"so i ain't got a thing to lose.\",\n \"take me to a place where i don't care,\",\n \"this is me and my liquor store blues. i'll take one shot for my pain,\",\n 'one drag for my sorrow.',\n 'get messed up today,',\n \"i'll be ok tomorrow.\",\n 'one shot for my pain,',\n 'one drag for my sorrow.',\n 'get messed up today,',\n \"i'll be ok tomorrow. here comes junior gong, i'm flying high like superman\",\n 'and thinking that i run the whole block,',\n \"i don't know if it's just because pineapple kush between my jaws\",\n \"has got me feeling like i'm on top give me this one shot for my pain,\",\n 'one drag for my sorrow.',\n 'get messed up today,',\n \"i'll be ok tomorrow.\",\n 'one shot for my pain,',\n 'one drag for my sorrow.',\n 'get messed up today,',\n \"i'll be ok tomorrow. now greetings to the world! you best believe! one, two, one, two, three oh yeah yeah\",\n 'oh yeah yeah yeah yeah, uh!',\n 'oh yeah yeah',\n 'oh yeah yeah yeah yeah, uh! never had much faith in love or miracles (miracles) uh!',\n 'never wanna put my heart on the line, uh!',\n 'but swimming in your water is something spiritual (spiritual) uh!',\n \"i'm born again every time you spend the night, uh! 'cause your sex takes me to paradise\",\n 'yeah your sex takes me to paradise',\n 'and it shows, yeah, yeah, yeah',\n \"'cause you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long',\n \"yeah you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long oh yeah yeah yeah yeah, uh!',\n 'oh yeah yeah',\n 'oh yeah yeah yeah yeah, uh! you bring me to my knees',\n 'you make me testify, uh!',\n 'you can make a sinner change his ways, uh!',\n \"open up your gates cause i can't wait to see the light, uh!\",\n \"and right there is where i wanna stay, uh! 'cause your sex takes me to paradise\",\n 'yeah your sex takes me to paradise',\n 'and it shows, yeah, yeah, yeah',\n \"'cause you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long',\n \"yeah you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long oh oh oh oh, yeah, yeah, yeah',\n 'can i just stay here',\n 'spend the rest of my days here',\n 'oh oh oh oh, yeah, yeah, yeah',\n \"can't i just stay here\",\n \"spend the rest of my days here 'cause you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long',\n \"yeah you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long oh yeah yeah yeah yeah, uh!',\n 'oh yeah yeah',\n 'oh yeah yeah yeah yeah, uh! hay tantas canciones',\n 'que puedo cantar para pasar el tiempo',\n 'y me estoy quedando sin cosas que hacer',\n 'para sacarte de mi mente',\n 'oh',\n 'todo lo que tengo es esta foto en un marco',\n 'que tengo muy cerca para ver tu cara todos los días contigo es donde',\n 'yo prefiero estar',\n 'pero estamos atrapados en esto',\n 'y es tan difícil',\n 'estás tan lejos',\n 'esta distancia me está matando',\n 'me gustaría que estuvieras aquí conmigo',\n 'pero estamos atrapados en esto.',\n 'y es tan difícil',\n 'estás tan lejos',\n 'esta distancia me está matando es tan difícil',\n 'es tan difícil',\n '¿dónde estamos?',\n '¿dónde estamos?',\n 'estás tan lejos',\n 'esta distancia me está matando',\n 'es tan difícil',\n 'es tan difícil',\n '¿dónde estamos?',\n '¿dónde estamos?',\n 'estás tan lejos',\n 'esta distancia me está matando ahora los minutos',\n 'se sienten como horas',\n 'y las horas se sienten como días',\n 'aunque estoy lejos',\n 'tu sabes que',\n 'no puedo estar en casa',\n 'pero vuelvo a casa pronto',\n 'vuelvo a casa pronto. todo lo que tengo es esta foto en un marco',\n 'que tengo muy cerca para ver tu cara todos los días',\n 'contigo es donde',\n 'yo prefiero estar',\n 'pero estamos atrapados en esto',\n 'y es tan difícil',\n 'estás tan lejos',\n 'esta distancia me está matando',\n 'me gustaría que estuvieras aquí conmigo',\n 'pero estamos atrapados en esto.',\n 'y es tan difícil',\n 'estás tan lejos ¿puedes oírme llorar?',\n 'oh',\n '¿puedes oírme llorar?',\n 'oh',\n '¿puedes oírme llorar?',\n 'oh contigo es donde',\n 'yo prefiero estar',\n 'pero estamos atrapados en esto',\n 'y es tan difícil',\n 'estás tan lejos',\n 'esta distancia me está matando',\n 'me gustaría que estuvieras aquí conmigo',\n 'pero estamos atrapados en esto.',\n 'y es tan difícil',\n 'estás tan lejos',\n 'esta distancia me está matando.',\n 'es tan difícil',\n 'es tan difícil',\n '¿dónde estamos?',\n '¿dónde estamos?',\n 'estás tan lejos',\n 'esta distancia me está matando',\n 'es tan difícil',\n 'es tan difícil',\n '¿dónde estamos?',\n '¿dónde estamos?',\n 'estás tan lejos',\n 'esta distancia me está matando hay tantas canciones',\n 'que puedo cantar para pasar el tiempo... ¿qué estás loco?',\n 'se está haciendo difícil esperar,',\n 'estoy tratando de hacerle ver,',\n 'que ella no sabe realmente',\n 'que yo estoy tratando de encontrar una manera,',\n 'y dile a ella todos los días, que sólo va de la mano',\n 'así que ...',\n 'yo no quiero ser,',\n 'el único que sabe',\n 'que alguien podría venir y apenas',\n 'dicen que el amor por mí,',\n 'estoy de pie temblando de tierra,',\n 'y estoy pensando que voy a perder, estribillo:',\n 'porque yo estoy perdiendo mi cabeza,',\n 'estoy perdiendo mi mente,',\n 'estoy perdiendo el control de mí mismo esta vez.',\n 'ella me tiene de perder la cabeza,',\n 'estoy perdiendo mi mente,',\n 'estoy perdiendo a mi manera,',\n 'pero yo creo que ella siente que ya estoy atrapado. ¿estás hablando conmigo?',\n 'ya estoy atrapado. me gustaría que me podía ver,',\n 'pero es que lo que',\n 'siente esto debe ser.',\n 'mi amor es como bala',\n 'todo lo que necesita es una inyección para mí para hacer estallar todo por la borda.',\n 'no quiero sentir que estoy perdiendo el tiempo,',\n 'va a estar con ustedes y nadie más.',\n 'hasta que me aviso,',\n 'necesito saber en este momento',\n 'porque yo he estado creo que me voy a perder estribillo:',\n 'porque yo estoy perdiendo mi cabeza,',\n 'estoy perdiendo mi mente,',\n 'estoy perdiendo el control de mí mismo esta vez.',\n 'ella me tiene de perder la cabeza,',\n 'estoy perdiendo mi mente,',\n 'estoy perdiendo a mi manera,',\n 'pero yo creo que ella siente que ya estoy atrapado. dame una oportunidad ...',\n 'pero chica que me pone nervioso,',\n 'a estas alturas ya debería haberme dado cuenta.',\n '¿y qué va a tomar',\n 'para la celestial ...',\n 'me estás volviendo loco! estribillo:',\n 'porque yo estoy perdiendo mi cabeza,',\n 'estoy perdiendo mi mente,',\n 'estoy perdiendo el control de mí mismo esta vez.',\n 'ella me tiene de perder la cabeza,',\n 'estoy perdiendo mi mente,',\n 'estoy perdiendo a mi manera,',\n 'pero yo creo que ella siente que ya estoy atrapado. hey, hey, hey',\n 'i got a condo in manhattan',\n \"baby girl, what's hatnin'?\",\n 'you and your ass invited',\n \"so gon' and get to clappin'\",\n 'go pop it for a player, pop-pop it for me',\n 'turn around and drop it for a player, drop-drop it for me',\n \"i'll rent a beach house in miami\",\n 'wake up with no jammies (nope)',\n 'lobster tail for dinner',\n 'julio, serve that scampi',\n 'you got it if you want it, got, got it if you want it',\n 'said you got it if you want it, take my wallet if you want it, now jump in the cadillac',\n \"(girl, let's put some miles on it)\",\n 'anything you want',\n '(just to put a smile on you)',\n 'you deserve it baby, you deserve it all',\n \"and i'm gonna give it to you cool jewelry shining so bright\",\n 'strawberry champagne on ice',\n \"lucky for you, that's what i like, that's what i like\",\n \"lucky for you, that's what i like, that's what i like\",\n 'sex by the fire at night',\n 'silk sheets and diamonds all white',\n \"lucky for you, that's what i like, that's what i like\",\n \"lucky for you, that's what i like, that's what i like i'm talkin' trips to puerto rico\",\n 'say the word and we go',\n 'you can be my fleeka',\n \"girl, i'll be a fleeko, mamacita\",\n \"i will never make a promise that i can't keep\",\n \"i promise that your smile ain't gon' never leave\",\n 'shopping sprees in paris',\n 'everything twenty-four karats',\n 'take a look in that mirror (take a look)',\n \"now tell me who's the fairest\",\n 'is it you? (is it you?) is it me? (is it me?)',\n \"say it's us (say it's us) and i'll agree, baby jump in the cadillac\",\n \"(girl, let's put some miles on it)\",\n 'anything you want',\n '(just to put a smile on you)',\n 'you deserve it baby, you deserve it all',\n \"and i'm gonna give it to you cool jewelry shining so bright\",\n 'strawberry champagne on ice',\n \"lucky for you, that's what i like, that's what i like\",\n \"lucky for you, that's what i like, that's what i like\",\n 'sex by the fire at night',\n 'silk sheets and diamonds all white',\n \"lucky for you, that's what i like, that's what i like\",\n \"lucky for you, that's what i like, that's what i like you say you want a good time\",\n 'well here i am, baby, here i am, baby',\n 'talk to me, talk to me, talk to me',\n \"talk to me, tell me what's on your mind\",\n \"what's on your mind\",\n 'if you want it, girl, come and get it',\n 'all this is here for you',\n 'tell me baby, tell me, tell me baby',\n 'what you tryna do cool jewelry shining so bright',\n 'strawberry champagne on ice',\n \"lucky for you, that's what i like, that's what i like (that's what i like)\",\n \"lucky for you, that's what i like, that's what i like\",\n 'sex by the fire at night',\n 'silk sheets and diamonds all white',\n \"lucky for you, that's what i like, that's what i like (that's what i like)\",\n \"lucky for you, that's what i like, that's what i like i wanna be a billionaire so f***in' bad\",\n 'buy all of the things i never had',\n 'uh, i wanna be on the cover of forbes magazine',\n 'smiling next to oprah and the queen oh every time i close my eyes',\n 'i see my name in shining lights',\n 'a different city every night oh right',\n 'i swear the world better prepare',\n \"for when i'm a billionaire yeah i would have a show like oprah\",\n 'i would be the host of, everyday christmas',\n 'give travie a wish list',\n \"i'd probably pull an angelina and brad pitt\",\n \"and adopt a bunch of babies that ain't never had s***\",\n 'give away a few mercedes like here lady have this',\n 'and last but not least grant somebody their last wish',\n \"it's been a couple months that i've been single so\",\n 'you can call me travie claus minus the ho ho',\n \"get it, hehe, i'd probably visit where katrina hit\",\n 'and damn sure do a lot more than fema did',\n \"yeah can't forget about me stupid\",\n 'everywhere i go imma have my own theme music oh every time i close my eyes',\n 'i see my name in shining lights',\n 'a different city every night oh right',\n 'i swear the world better prepare',\n \"for when i'm a billionaire\",\n \"oh ooh oh ooh for when i'm a billionaire\",\n \"oh ooh oh ooh for when i'm a billionaire i'll be playing basketball with the president\",\n 'dunking on his delegates',\n \"then i'll compliment him on his political etiquette\",\n 'toss a couple milli in the air just for the heck of it',\n 'but keep the five, twenties tens and bens completely separate',\n \"and yeah i'll be in a whole new tax bracket\",\n 'we in recession but let me take a crack at it',\n \"i'll probably take whatever's left and just split it up\",\n 'so everybody that i love can have a couple bucks',\n 'and not a single tummy around me would know what hungry was',\n 'eating good sleeping soundly',\n 'i know we all have a similar dream',\n 'go in your pocket pull out your wallet',\n \"and put it in the air and sing i wanna be a billionaire so f***in' bad\",\n 'buy all of the things i never had',\n 'uh, i wanna be on the cover of forbes magazine',\n 'smiling next to oprah and the queen',\n 'oh every time i close my eyes i see my name in shining lights',\n 'a different city every night all right',\n \"i swear the world better prepare for when i'm a billionaire\",\n \"i wanna be a billionaire so f***in' bad oh every time i close my eyes\",\n 'i see my name in shining lights',\n 'a different city every night oh',\n 'i swear the world better prepare',\n \"for when i'm a billionaire i wanna be a billionaire so f***in' bad! oh, her eyes, her eyes make the stars look like they're not shining\",\n 'her hair, her hair falls perfectly without her trying',\n \"she's so beautiful\",\n \"and i tell her everyday. yeah, i know, i know when i compliment her, she won't believe me\",\n \"and it's so, it's so sad to think that she doesn't see what i see\",\n 'but every time she ask me do i look okay?',\n 'i say when i see your face',\n \"there's not a thing that i would change\",\n \"'cause you're amazing\",\n 'just the way you are and when you smile',\n 'the whole world stops and stares for a while',\n \"'cause girl, you're amazing\",\n \"just the way you are her lips, her lips, i could kiss them all day if she'd let me\",\n \"her laugh her laugh, she hates but i think it's so sexy\",\n \"she's so beautiful\",\n \"and i tell her everyday oh, you know, you know, you know i'd never ask you to change\",\n \"if perfect's what you're searching for, then just stay the same\",\n \"so don't even bother asking if you look okay\",\n \"you know i'll say when i see your face\",\n \"there's not a thing that i would change\",\n \"'cause girl you're amazing\",\n 'just the way you are and when you smile',\n 'the whole world stops and stares for a while',\n \"'cause girl, you're amazing\",\n 'just the way you are the way you are',\n 'the way you are',\n \"girl, you're amazing\",\n 'just the way you are when i see your face',\n \"there's not a thing that i would change\",\n \"'cause girl you're amazing\",\n 'just the way you are and when you smile',\n 'the whole world stops and stares for a while',\n \"'cause girl, you're amazing\",\n 'just the way you are.',\n \"yeah today i don't feel like doing anything\",\n 'i just wanna lay in my bed',\n \"don't feel like picking up my phone\",\n 'so leave a message at the tone',\n \"'cause today i swear i'm not doing anything uh i'm gonna kick my feet up and stare at the fan\",\n 'turn the t.v. on',\n 'throw my hand in my pants',\n \"nobody's gon' tell me i cant, no i'll be loungin' on the couch just chillin' in my snuggie\",\n 'flip to mtv so they can teach me how to dougie',\n \"'cause in my castle i'm the freakin' man\",\n 'oh yes i said it',\n 'i said it',\n \"i said it 'cause i can today i don't feel like doing anything\",\n 'i just wanna lay in my bed',\n \"don't feel like picking up my phone\",\n 'so leave a message at the tone',\n \"'cause today i swear i'm not doing anything nothing at all\",\n 'ooh hoo ooh hoo',\n 'hoo ooh ooh',\n 'nothing at all',\n 'ooh hoo ooh hoo',\n \"hoo ooh ooh tomorrow i'll wake up do some p90x\",\n 'meet a really nice girl have some really nice sex',\n \"and she's gonna scream out this is great i might mess around and get my college degree\",\n 'i bet my old man will be so proud of me',\n \"but sorry pops you'll just have to wait\",\n 'oh yes i said it',\n 'i said it',\n \"i said it 'cause i can today i don't feel like doing anything\",\n 'i just wanna lay in my bed',\n \"don't feel like picking up my phone\",\n 'so leave a message at the tone',\n \"'cause today i swear i'm not doing anything no i ain't gonna comb my hair\",\n \"'cause i ain't goin' anywhere\",\n 'no no no no no no no no no oh',\n \"i'll just strut in my birthday suit\",\n 'and let everything hang loose',\n \"yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah oh, today i don't feel like doing anything\",\n 'i just wanna lay in my bed',\n \"don't feel like picking up my phone\",\n 'so leave a message at the tone',\n \"'cause today i swear i'm not doing anything nothing at all\",\n 'ooh hoo ooh hoo',\n 'hoo ooh ooh',\n 'nothing at all',\n 'ooh hoo ooh hoo',\n 'hoo ooh ooh',\n \"nothing at all easy come easy go, that's just how you live\",\n 'oh, take, take, take it all but you never give',\n \"should've known you was trouble from the first kiss\",\n 'had your eyes wide open, why were they open gave you all i had and you tossed it in the trash',\n 'you tossed it in the trash, you did',\n 'to give me all your love is all i ever asked',\n \"'cause what you don't understand is\",\n \"i'd catch a grenade for ya\",\n 'throw my hand on a blade for ya',\n \"i'd jump in front of a train for ya\",\n \"you know i'd do anything for ya\",\n 'oh oh oh oh oh i would go through all this pain',\n 'take a bullet straight right through my brain',\n 'yes, i would die for you, baby',\n \"but you won't do the same no, no, no, no black, black, black and blue, beat me 'til i'm numb\",\n \"tell the devil i said, hey, when you get back to where you're from\",\n \"mad woman, bad woman, that's just what you are, yeah\",\n \"you'll smile in my face then rip the brakes out my car gave you all i had and you tossed it in the trash\",\n 'you tossed it in the trash, yes, you did',\n 'to give me all your love is all i ever asked',\n \"'cause what you don't understand is\",\n \"i'd catch a grenade for ya\",\n 'throw my hand on a blade for ya',\n \"i'd jump in front of a train for ya\",\n \"you know i'd do anything for ya\",\n 'oooh',\n 'i would go through all this pain',\n 'take a bullet straight right through my brain',\n 'yes, i would die for ya, baby',\n \"but you won't do the same if my body was on fire\",\n \"ooh, you'd watch me burn down in flames\",\n \"you said you loved me, you're a liar\",\n \"'cause you never, ever, ever did, baby but darling, i'd still catch a grenade for ya\",\n 'throw my hand on a blade for ya',\n \"i'd jump in front of a train for ya\",\n \"you know i'd do anything for ya i would go through all this pain\",\n 'take a bullet straight right through my brain',\n 'yes, i would die for you, baby',\n \"but you won't do the same no, you won't do the same\",\n \"you wouldn't do the same\",\n 'ooh, you never do the same',\n 'no, no, no, no this hit, that ice cold',\n 'michelle pfeiffer, that white gold',\n 'this one for them hood girls',\n 'them good girls straight masterpieces',\n \"stylin', whilen, livin' it up in the city\",\n 'got chucks on with saint laurent',\n \"got kiss myself, i'm so pretty i'm too hot (hot damn)\",\n 'called a police and a fireman',\n \"i'm too hot (hot damn)\",\n 'make a dragon wanna retire man',\n \"i'm too hot (hot damn)\",\n 'say my name you know who i am',\n \"i'm too hot (hot damn)\",\n \"am i bad 'bout that money, break it down girls hit your hallelujah (whoo)\",\n 'girls hit your hallelujah (whoo)',\n 'girls hit your hallelujah (whoo)',\n \"'cause uptown funk gon' give it to you\",\n \"'cause uptown funk gon' give it to you\",\n \"'cause uptown funk gon' give it to you\",\n 'saturday night and we in the spot',\n \"don't believe me just watch (come on) don't believe me just watch uh don't believe me just watch\",\n \"don't believe me just watch\",\n \"don't believe me just watch\",\n \"don't believe me just watch\",\n 'hey, hey, hey, oh stop, wait a minute',\n 'fill my cup, put some liquor in it',\n 'take a sip, sign a check',\n 'julio, get the stretch',\n 'ride to harlem, hollywood',\n 'jackson, mississippi',\n \"if we show up, we gon' show out\",\n \"smoother than a fresh jar of skippy i'm too hot (hot damn)\",\n 'called a police and a fireman',\n \"i'm too hot (hot damn)\",\n 'make a dragon wanna retire man',\n \"i'm too hot (hot damn)\",\n 'bitch say my name you know who i am',\n \"i'm too hot (hot damn)\",\n \"am i bad 'bout that money\",\n 'break it down girls hit your hallelujah (whoo)',\n 'girls hit your hallelujah (whoo)',\n 'girls hit your hallelujah (whoo)',\n \"'cause uptown funk gon' give it to you\",\n \"'cause uptown funk gon' give it to you\",\n \"'cause uptown funk gon' give it to you\",\n 'saturday night and we in the spot',\n \"don't believe me just watch (come on) don't believe me just watch uh don't believe me just watch uh\",\n \"don't believe me just watch uh\",\n \"don't believe me just watch\",\n \"don't believe me just watch\",\n 'hey, hey, hey, oh before we leave',\n \"lemmi tell y'all a lil' something\",\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up uh',\n 'i said uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up come on, dance, jump on it',\n 'if you sexy then flaunt it',\n 'if you freaky then own it',\n \"don't brag about it, come show me come on, dance\",\n 'jump on it',\n 'if you sexy then flaunt it',\n \"well it's saturday night and we in the spot\",\n \"don't believe me just watch come on! don't believe me just watch uh don't believe me just watch uh\",\n \"don't believe me just watch uh\",\n \"don't believe me just watch\",\n \"don't believe me just watch\",\n 'hey, hey, hey, oh uptown funk you up',\n 'uptown funk you up (say what?)',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up (say what?)',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up (say what?)',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up',\n 'uptown funk you up (say what?)',\n \"uptown funk you up let's take our time tonight, girl\",\n \"above us all the stars are watchin'\",\n \"there's no place i'd rather be in this world\",\n \"your eyes are where i'm lost in\",\n 'underneath the chandelier',\n \"we're dancin' all alone\",\n \"there's no reason to hide\",\n \"what we're feelin' inside\",\n \"right now! so baby let's just turn down the lights\",\n 'and close the door',\n 'oooh i love that dress',\n \"but you won't need it anymore\",\n \"no you won't need it no more\",\n \"let's just kiss 'til we're naked, baby versace on the floor\",\n 'oooh take it off for me, for me, for me, for me now, girl',\n 'versace on the floor',\n 'oooh take it off for me, for me, for me, for me now, girl i unzip the back to watch it fall',\n 'while i kiss your neck and shoulders',\n \"no don't be afraid to show it off\",\n \"i'll be right here ready to hold you\",\n \"girl you know you're perfect from\",\n 'your head down to your heels',\n \"don't be confused by my smile\",\n \"'cause i ain't ever been more for real, for real so just turn down the lights (down the lights)\",\n 'and close the door (close the door)',\n 'oooh i love that dress',\n \"but you won't need it anymore\",\n \"no you won't need it no more\",\n \"let's just kiss 'til we're naked, baby versace on the floor\",\n 'ooh take it off for me, for me, for me, for me now, girl',\n 'versace on the floor',\n 'ooh take it off for me, for me, for me, for me now, girl',\n \"dance (it's warmin' up) can you feel it?\",\n \"(it's warmin' up) can you feel it?\",\n \"(it's warmin' up) can you feel it, baby?\",\n \"it's warmin' up\",\n \"oh, seems like you're ready for more, more, more\",\n \"let's just kiss 'til we're naked ooh, versace on the floor, hey baby\",\n 'take it off for me, for me, for me, for me now, girl',\n 'versace on the floor',\n 'oh take it off for me, for me, for me, for me now, girl versace on the floor',\n \"floor floor it's a beautiful night ,\",\n \"we're looking for something dumb to do\",\n 'hey baby',\n 'i think i want to marry you is it the look in your eyes?',\n 'or is it these dancing juice?',\n 'who cares baby',\n 'i think i wanna marry you well i know this little chapel on the boulevard we can go',\n 'no one will know',\n \"oh come on girl who cares if we're trashed got a pocket full of cash we can blow\",\n 'shots of patron',\n \"and it's on girl don't say no, no, no, no-no\",\n 'just say yeah, yeah, yeah, yeah-yeah',\n \"and we'll go, go, go, go-go\",\n \"if you're ready, like i'm ready cause it's a beautiful night\",\n \"we're looking for something dumb to do\",\n 'hey baby',\n 'i think i wanna marry you is it the look in your eyes?',\n 'or is it the dancing juice?',\n 'who cares baby',\n \"i think i wanna marry you i'll go get a ring let the choir bells sing like oooh\",\n 'so what you wanna do?',\n \"let's just run girl if we wake up and you wanna break up that's cool\",\n \"no, i won't blame you\",\n \"it was fun girl don't say no, no, no, no-no\",\n 'just say yeah, yeah, yeah, yeah-yeah',\n \"and we'll go, go, go, go-go\",\n \"if you're ready, like i'm ready cause it's a beautiful night,\",\n \"we're looking for something dumb to do\",\n 'hey baby',\n 'i think i wanna marry you. is it the look in your eyes?',\n 'or is it this dancing juice?',\n 'who cares baby,',\n 'i think i wanna marry you. just say i do,',\n 'tell me right now baby,',\n 'tell me right now baby, baby',\n 'just say i do',\n 'tell me right now baby,',\n \"tell me right now baby, baby oh it's a beautiful night\",\n \"we're looking for something dumb to do\",\n 'hey baby',\n 'i think i wanna marry you is it the look in your eyes?',\n 'or is it this dancing juice?',\n 'who cares baby',\n 'i think i wanna marry you. if you ever find yourself stuck in the middle of the sea,',\n \"i'll sail the world to find you\",\n \"if you ever find yourself lost in the dark and you can't see,\",\n \"i'll be the light to guide you find out what we're made of\",\n 'when we are called to help our friends in need you can count on me like one two three',\n \"i'll be there\",\n 'and i know when i need it i can count on you like four three two',\n \"you'll be there\",\n \"'cause that's what friends are supposed to do, oh yeah whoa, whoa\",\n 'oh, oh',\n \"yeah, yeah if you tossin' and you're turnin' and you just can't fall asleep\",\n \"i'll sing a song\",\n 'beside you',\n 'and if you ever forget how much you really mean to me',\n 'everyday i will',\n 'remind you ooh',\n \"find out what we're made of\",\n 'when we are called to help our friends in need you can count on me like one two three',\n \"i'll be there\",\n 'and i know when i need it i can count on you like four three two',\n \"you'll be there\",\n \"'cause that's what friends are supposed to do, oh yeah oh, oh\",\n \"yeah, yeah you'll always have my shoulder when you cry\",\n \"i'll never let go\",\n 'never say goodbye',\n 'you know you can count on me like one two three',\n \"i'll be there\",\n 'and i know when i need it i can count on you like four three two',\n \"and you'll be there\",\n \"'cause that's what friends are supposed to do, oh yeah oh, oh\",\n \"you can count on me 'cause i can count on you same bed but it feels just\",\n 'a little bit bigger now',\n 'our song on the radio',\n \"but it don't sound the same\",\n 'when our friends talk about you',\n 'all it does is just tear me down',\n 'cause my heart breaks a little',\n 'when i hear your name',\n 'it all just sounds like (oooooh)',\n 'mmm too young too dumb to realize',\n \"that i should've bought you flowers\",\n 'and held your hand',\n \"should've gave you all my hours\",\n 'when i had the chance',\n 'take you to every party',\n 'cause all you wanted to do was dance',\n 'now my baby is dancing',\n \"but she's dancing with another man my pride, my ego, my needs and my selfish ways\",\n 'caused a good strong woman like you to walk out my life',\n 'now i never never get to clean up the mess i made',\n 'ooh and it hunts me every time i close my eyes',\n 'it all just sounds like (oooooh)',\n 'mmm too young too dumb to realize',\n \"that i should've bought you flowers\",\n 'and held your hand',\n \"should've gave you all my hours\",\n 'when i had the chance',\n 'take you to every party',\n 'cause all you wanted to do was dance',\n 'now my baby is dancing',\n \"but she's dancing with another man although it hurts\",\n \"i'll be the first to say\",\n 'that i was wrooooong',\n \"oooh i know i'm probably much too late\",\n 'to try and apologize for my mistakes',\n 'but i just want you to know i hope he buys you flowers',\n 'i hope he holds your hand',\n 'give you all his hours',\n 'when he has the chance',\n 'take you to every party',\n 'cause i remember how much',\n 'you loved to dance',\n \"do all the things i should've done\",\n 'when i was your man',\n \"do all the things i should've done\",\n 'when i was your man tonight',\n 'i just want to take you higher',\n 'throw your hands up in the sky',\n \"let's set this party off right players, put yo' pinky rings up to the moon\",\n \"girls, what y'all trying to do?\",\n 'twenty four karat magic in the air',\n 'head to toe so player',\n \"look out uh pop pop, it's show time (show time)\",\n 'show time (show time)',\n \"guess who's back again?\",\n \"oh they don't know? (go on tell 'em)\",\n \"oh they don't know? (go on tell 'em)\",\n \"i bet they know soon as we walk in (showin' up)\",\n 'wearing cuban links (ya)',\n 'designer minks (ya)',\n \"inglewood's finest shoes (whoop, whoop)\",\n \"don't look too hard might hurt ya'self\",\n \"known to give the color red the blues oh shit, i'm a dangerous man with some money in my pocket (keep up)\",\n 'so many pretty girls around me and they waking up the rocket (keep up)',\n \"why you mad, fix ya face, ain't my fault y'all be jocking (keep up) players only, come on\",\n 'put your pinky rings up to the moon',\n \"girls, what y'all trying to do?\",\n 'twenty four karat magic in the air',\n 'head to toe so player',\n 'uh, look out! second verse for the hustlas (hustlas) gangstas (gangstas)',\n 'bad bitches and ya ugly ass friends (haha)',\n 'can i preach (uh oh) can i preach (uh oh)',\n \"i gotta show 'em how a pimp get it in\",\n 'first, take your sip (sip), do your dip (dip)',\n \"spend your money like money ain't shit (whoop, whoop)\",\n 'we too fresh',\n 'got to blame in on jesus',\n \"hashtag blessed, they ain't ready for me i'm a dangerous man with some money in my pocket (keep up)\",\n 'so many pretty girls around me and they waking up the rocket (keep up)',\n \"why you mad, fix ya face, ain't my fault y'all be jocking (keep up) players only, come on\",\n 'put your pinky rings up to the moon',\n 'hey girls',\n \"what y'all trying to do? (what y'all trying to do?)\",\n 'twenty four karat magic in the air',\n 'head to toe so player',\n 'uh, look out! (wooh) everywhere i go they be like',\n 'ooh, so player',\n 'everywhere i go they be like (ooh, so player ooh)',\n 'oh everywhere i go they be like (ooh, so player ooh) now, now, now watch me break it down like (uh)',\n 'twenty four karat, twenty four karat magic',\n \"what's that sound (twenty four karat, twenty four karat magic)\",\n 'come on now',\n 'twenty four karat, twenty four karat magic',\n \"don't fight the feeling, invite the feeling just put your pinky rings up to the moon\",\n \"girls, what y'all trying to do? (tell me what y'all trying to do)\",\n 'twenty four karat magic in the air',\n 'head to toe so player (hands up!)',\n 'put your pinky rings up to the moon',\n \"girls, what y'all trying to do? (do)\",\n 'twenty four karat magic in the air',\n 'head to toe so player (twenty four karat) uh, look out (twenty four karat magic, magic, magic) if you ever leave me, baby,',\n 'leave some morphine at my door',\n \"'cause it would take a whole lot of medication\",\n 'to realize what we used to have,',\n \"we don't have it anymore. there's no religion that could save me\",\n 'no matter how long my knees are on the floor (ooh)',\n \"so keep in mind all the sacrifices i'm makin'\",\n 'to keep you by my side',\n \"to keep you from walkin' out the door. 'cause there'll be no sunlight\",\n 'if i lose you, baby',\n \"there'll be no clear skies\",\n 'if i lose you, baby',\n 'just like the clouds',\n 'my eyes will do the same, if you walk away',\n \"everyday it'll rain, rain, ra-a-a-ain i'll never be your mother's favorite\",\n \"your daddy can't even look me in the eye\",\n \"ooh, if i was in their shoes, i'd be doing the same thing\",\n 'sayin\\' \"there goes my little girl',\n 'walkin\\' with that troublesome guy\" but they\\'re just afraid of something they can\\'t understand',\n \"ooh, but little darlin' watch me change their minds\",\n \"yeah for you i'll try, i'll try, i'll try, i'll try\",\n \"and pick up these broken pieces 'til i'm bleeding\",\n \"if that'll make you mine 'cause there'll be no sunlight\",\n 'if i lose you, baby',\n \"there'll be no clear skies\",\n 'if i lose you, baby',\n 'just like the clouds',\n 'my eyes will do the same, if you walk away',\n \"everyday it'll rain, rain, ra-a-a-ain oh, don't you say (don't you say) goodbye (goodbye),\",\n \"don't you say (don't you say) goodbye (goodbye)\",\n \"i'll pick up these broken pieces 'til i'm bleeding\",\n \"if that'll make it right 'cause there'll be no sunlight\",\n 'if i lose you, baby',\n \"there'll be no clear skies\",\n 'if i lose you, baby',\n 'and just like the clouds',\n 'my eyes will do the same, if you walk away',\n \"everyday it'll rain, rain, ra-a-a-ain give me all, give me all, give me all attention baby\",\n 'i got to tell you a little something about yourself',\n \"you're wonderful, flawless, ooh you're a sexy lady\",\n \"but you walk around here like you wanna be someone else ooooooooohhhhhhhhhhh i know that you don't know it, but you're fine, so fine\",\n '(fine, so fine)',\n \"ooooooooooohhhhhhhhh oh girl i'm gonna show you when you're mine, oh mine(mine, oh mine) treasure, that is what you are\",\n \"honey you're my golden star\",\n 'i know you could make my wish come true',\n 'if you let me treasure you',\n 'if you let me treasure you oh oooooh pretty girl, pretty girl, pretty girl you should be smiling',\n 'a girl like you should never look so blue',\n \"you're everything i see in my dreams\",\n \"i wouldn't say that to you if it wasn't true oooooooooohhhhhhhhhhhh i know that you don't know it, but you're fine, so fine\",\n \"(fine, so fine) ooooooooooohhhhhhhhhhh oh girl i'm gonna show you when you're mine, oh mine(mine, oh mine) treasure, that is what you are\",\n \"honey you're my golden star\",\n 'i know you could make my wish come true',\n 'if you let me treasure you',\n 'if you let me treasure you you are my treasure, you are my treasure',\n 'you are my treasure, yeah, you you you, you are',\n 'you are my treasure, you are my treasure',\n 'you are my treasure, yeah, you you you, you are treasure, that is what you are',\n \"honey you're my golden star\",\n 'i know you can make my wish come true',\n 'if you let me treasure you',\n \"if you let me treasure you i know you're somewhere out there\",\n 'somewhere far away',\n 'i want you back',\n 'i want you back',\n \"my neighbors think i'm crazy\",\n \"but they don't understand\",\n \"you're all i have\",\n \"you're all i have at night when the stars\",\n 'light up my room',\n 'i sit by myself',\n 'talking to the moon',\n \"tryin' to get to you\",\n \"in hopes you're on\",\n 'the other side',\n 'talking to me too',\n 'or am i a fool',\n 'who sits alone',\n \"talking to the moon oh i'm feeling like i'm famous\",\n 'the talk of the town',\n \"they say i've gone mad\",\n \"yeah i've gone mad\",\n \"but they don't know what i know 'cause when the sun goes down\",\n \"someone's talking back\",\n \"yeah they're talking back at night when the stars\",\n 'light up my room',\n 'i sit by myself',\n 'talking to the moon',\n \"tryin' to get to you\",\n \"in hopes you're on\",\n 'the other side',\n 'talking to me too',\n 'or am i a fool',\n 'who sits alone',\n 'talking to the moon (ah, ah, ah) do you ever hear me calling?',\n '(ah) oh oh oh',\n '(ah) oh oh oh',\n \"'cause every night\",\n \"i'm talking to the moon\",\n \"still trying to get to you in hopes you're on\",\n 'the other side',\n 'talking to me too',\n 'or am i a fool',\n 'who sits alone',\n \"talking to the moon i know you're somewhere out there\",\n 'somewhere far away well looky here looky here ah what do we have?',\n 'another pretty thing ready for me to grab',\n \"but little does she know that i'm a wolf in sheeps clothing\",\n \"'cause at the end of the night it is her i'll be holding i love you so\",\n \"that's what you'll say,\",\n \"you'll tell me baby, baby please don't go away\",\n 'but when i play, i never stay',\n \"to every girl that i meet here, this is what i'll say, run run runaway, runaway baby\",\n 'before i put my spell on you',\n 'you better get get getaway, getaway darling',\n \"'cause everything you heard is true you poor little heart will end up alone\",\n \"'cause lord knows i'm a rolling stone\",\n 'so you better run run runaway, runaway baby',\n 'uh, ah yeah well let me think, let me think, ah what should i do?',\n \"so many eager young bunnies that i'd like to pursue\",\n \"now even though they're eating out the palm of my hand\",\n \"there's only one carrot and they all gotta share it i love you so\",\n \"that's what you'll say,\",\n \"you'll tell me baby, baby please don't go away\",\n 'but when i play, i never stay',\n \"to every girl that i meet here, this is what i'll say, run run runaway, runaway baby\",\n 'before i put my spell on you',\n 'you better get get getaway, getaway darling',\n \"'cause everything you heard is true you poor little heart will end up alone\",\n \"'cause lord knows i'm a rolling stone\",\n 'so you better run run runaway, runaway baby',\n \"uh, check it out see i ain't tryna hurt you baby\",\n 'no no no i just want to work you baby',\n \"see i ain't tryna hurt you baby\",\n 'no no no i just want to work you baby if you are scared, you better run (you better run)',\n 'you better run, (you better run)',\n 'you better run, (you better run)',\n 'you better, you better, you better run run runaway, runaway baby',\n 'before i put my spell on you',\n 'you better get get getaway, getaway darling',\n \"'cause everything you heard is true you poor little heart will end up alone\",\n \"'cause lord knows i'm a rolling stone\",\n 'so you better run run runaway, runaway baby oh yeah yeah',\n 'oh yeah yeah yeah yeah',\n 'ooh!',\n 'oh yeah yeah',\n 'oh yeah yeah yeah yeah',\n 'ooh! never had much faith in love or miracles',\n 'never wanna put my heart on the line',\n 'but swimming in your world is something spiritual',\n \"i'm born again every time you spend the night cause your sex takes me to paradise\",\n 'yeah your sex takes me to paradise',\n 'and it shows, yeah, yeah, yeah',\n \"cause you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long',\n \"yeah you make me feel like, i've been locked out of heaven\",\n 'for too long, for too long oh yeah yeah yeah yeah',\n 'ooh!',\n 'oh yeah yeah',\n 'oh yeah yeah yeah yeah',\n 'ooh! you bring me to my knees',\n 'you make me testify',\n 'you can make a sinner change his ways',\n \"open up your gates cause i can't wait to see the light\",\n 'and right there is where i wanna stay cause your heart takes me to paradise',\n 'yeah your heart takes me to paradise',\n 'and it shows, yeah, yeah, yeah',\n \"cause you make feel like, i've been locked out of heaven\",\n 'for too long, for too long',\n \"yeah you make feel like, i've been locked out of heaven\",\n 'for too long, for too long oh oh oh oh, yeah, yeah, yeah',\n \"can't i just stay here\",\n 'spend the rest of my days here',\n 'oh, oh, oh, oh, yeah, yeah, yeah',\n \"can't i just stay here\",\n \"spend the rest of my days here cause you make feel like, i've been locked out of heaven\",\n 'for too long, for too long',\n \"yeah you make feel like, i've been locked out of heaven\",\n 'for too long, for too long oh yeah yeah yeah yeah',\n 'ooh!',\n 'oh yeah yeah',\n 'oh yeah yeah yeah yeah',\n 'oh yeah yeah year yeah',\n \"ooh! i've been working hard so long\",\n 'seems like pain has been my only friend',\n \"my fragile heart's been done so wrong\",\n \"i wondered if i'd ever heal again ohh just like all the seasons never stay the same\",\n 'all around me i can feel a change (ohh) chorus',\n 'i will break these chains that bind me, happiness will find me',\n 'leave the past behind me, today my life begins',\n \"a whole new world is waiting it's mine for the taking\",\n 'i know i can make it, today my life begins yesterday has come and gone',\n \"and i've learnt how to leave it where it is\",\n 'and i see that i was wrong',\n 'for ever doubting i could win ohh just like all the seasons never stay the same',\n 'all around me i can feel a change (ohh) i will break these chains that bind me, happiness will find me',\n 'leave the past behind me, today my life begins',\n \"a whole new world is waiting it's mine for the taking\",\n \"i know i can make it, today my life begins life's too short to have regrets\",\n \"so i'm learning now to leave it in the past and try to forget\",\n 'only have one life to live',\n 'so you better make the best of it i will break these chains that bind me, happiness will find me',\n 'leave the past behind me, today my life begins',\n \"a whole new world is waiting it's mine for the taking\",\n 'i know i can make it, today my life begins i will break these chains that bind me, happiness will find me',\n 'leave the past behind me, today my life begins',\n \"a whole new world is waiting it's mine for the taking\",\n 'i know i can make it, today my life begins',\n 'today my life begins... everyday i wake up next to an angel',\n 'more beautiful than words could say',\n \"they said it wouldn't work but what did they know?\",\n \"'cause years have passed and we're still here today never in my dreams did i think that this would happen to me as i stand here before my woman\",\n \"i can't fight back the tears in my eyes\",\n 'oh, how could i be so lucky',\n \"i must've done something right\",\n 'and i promise to love her for the rest of my life seems like yesterday when she first said hello',\n \"funny how time flies when you're in love\",\n 'it took us a lifetime to find each other',\n \"it was worth the wait 'cause i finally found the one never in my dreams did i think that this would happen to me as i stand here before my woman\",\n \"i can't fight back the tears in my eyes\",\n 'oh how could i be so lucky',\n \"i must've done something right\",\n 'and i promise to love her for the rest of my life with everything happening today',\n \"you don't know whether you're coming or going\",\n \"but you think that you're on your way\",\n \"life lined up on the mirror don't blow it look at me when i'm talkin' to you\",\n \"you looking at me but i'm lookin' through you\",\n 'i see the blood in your eyes',\n 'i see the love in disguise',\n 'i see the pain hidden in your pride',\n \"i see you're not satisfied\",\n \"and i don't see nobody else\",\n \"i see myself i'm looking at the mirror on the wall, here we are again\",\n 'through my rise and fall',\n \"you've been my only friend\",\n 'you told me that they can understand the man i am',\n \"so why are we here talkin' to each other again uh, i see the truth in your lies\",\n 'i see nobody by your side',\n \"but i'm with you when you re all alone\",\n \"and you correct me when i'm lookin' wrong\",\n 'i see that guilt beneath the shame',\n 'i see your soul through your window pain',\n 'i see the scars that remain',\n \"i see you wayne, i'm lookin' at the mirror on the wall, here we are again\",\n 'through my rise and fall',\n \"you've been my only friend\",\n 'you told me that they can understand the man i am',\n \"so why are we here talkin' to each other again lookin' at me now i can see my past\",\n \"damn i look just like my fuckin' dad\",\n \"light it up, that's smoke at mirrors\",\n 'i even look good in the broken mirror',\n \"i see my momma smile that's a blessin'\",\n 'i see the change, i see the message',\n 'and no message could been any clearer',\n \"so i'm starting with the man in the mirror on the wall, (mj taught me that)\",\n 'here we are again',\n 'through my rise and fall',\n \"you've been my only friend (take them to mars man)\",\n 'you told me that they can understand the man i am',\n \"so why are we here talkin' to each other again\",\n 'uh mirror on the wall, here we are again',\n 'through my rise and fall',\n \"you've been my only friend\",\n 'you told me that they can understand the man i am',\n \"so why are we here talkin' to each other again\",\n 'mirror on the wall',\n \"hey bp, looks like i did take 'em to mars this time so why are we talkin' to each other again man, look at you, been walking in here looking all pretty and angry and mean and good\",\n 'haha',\n \"now i know you didn't get your hair done so you could just sit down and just sit still\",\n \"hey, we tryna have a good time tonight, let's go over here (let's go over here!) it's my birthday\",\n \"(no, it's not)\",\n 'but i still look good though',\n '(high comb hot)',\n 'i bet you want an autograph',\n 'for you and your friends',\n ...]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00002-a022137a-0ee5-4b65-9207-a97b64fc0436",
        "deepnote_cell_type": "code"
      },
      "source": "!pip install -U text-gen",
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting text-gen\n  Downloading text_gen-1.2.0-py3-none-any.whl (7.8 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from text-gen) (0.8.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from text-gen) (1.1.5)\nRequirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (from text-gen) (2.4.3)\nCollecting parameter-sherpa\n  Downloading parameter-sherpa-1.0.6.tar.gz (513 kB)\n\u001b[K     |████████████████████████████████| 513 kB 812 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from text-gen) (3.3.3)\nCollecting deepsegment\n  Downloading deepsegment-2.3.1-py2.py3-none-any.whl (20 kB)\nRequirement already satisfied: setuptools>=47.1.1 in /opt/conda/lib/python3.7/site-packages (from text-gen) (49.6.0.post20201009)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from text-gen) (1.19.5)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from text-gen) (2.4.1)\nCollecting seqtag-keras\n  Downloading seqtag_keras-1.0.6-py2.py3-none-any.whl (21 kB)\nCollecting pydload\n  Downloading pydload-1.0.9-py2.py3-none-any.whl (16 kB)\nCollecting progressbar2\n  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras->text-gen) (5.3.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras->text-gen) (2.10.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras->text-gen) (1.5.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras->text-gen) (1.15.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->text-gen) (1.3.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->text-gen) (2.8.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->text-gen) (7.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->text-gen) (0.10.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->text-gen) (2.4.7)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->text-gen) (2020.5)\nRequirement already satisfied: pymongo>=3.5.1 in /opt/conda/lib/python3.7/site-packages (from parameter-sherpa->text-gen) (3.11.3)\nRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from parameter-sherpa->text-gen) (0.24.1)\nRequirement already satisfied: flask>=0.12.2 in /opt/conda/lib/python3.7/site-packages (from parameter-sherpa->text-gen) (1.1.2)\nCollecting GPyOpt>=1.2.5\n  Downloading GPyOpt-1.2.6.tar.gz (56 kB)\n\u001b[K     |████████████████████████████████| 56 kB 3.7 MB/s  eta 0:00:01\n\u001b[?25hCollecting enum34\n  Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\nRequirement already satisfied: click>=5.1 in /opt/conda/lib/python3.7/site-packages (from flask>=0.12.2->parameter-sherpa->text-gen) (7.1.2)\nRequirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask>=0.12.2->parameter-sherpa->text-gen) (1.0.1)\nRequirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask>=0.12.2->parameter-sherpa->text-gen) (1.1.0)\nRequirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask>=0.12.2->parameter-sherpa->text-gen) (2.11.2)\nCollecting GPy>=1.8\n  Downloading GPy-1.9.9.tar.gz (995 kB)\n\u001b[K     |████████████████████████████████| 995 kB 13.2 MB/s eta 0:00:01\n\u001b[?25hCollecting paramz>=0.9.0\n  Downloading paramz-0.9.5.tar.gz (71 kB)\n\u001b[K     |████████████████████████████████| 71 kB 2.4 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=0.12.2->parameter-sherpa->text-gen) (1.1.1)\nRequirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.7/site-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt>=1.2.5->parameter-sherpa->text-gen) (4.4.2)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->parameter-sherpa->text-gen) (1.0.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->parameter-sherpa->text-gen) (2.1.0)\nCollecting python-utils>=2.3.0\n  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pydload->deepsegment->text-gen) (2.25.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment->text-gen) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment->text-gen) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment->text-gen) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment->text-gen) (1.26.2)\nCollecting seqeval==0.0.3\n  Downloading seqeval-0.0.3-py3-none-any.whl (5.6 kB)\nCollecting keras\n  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n\u001b[K     |████████████████████████████████| 377 kB 17.9 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 5.4 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras->text-gen) (1.1.2)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (0.2.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (1.6.3)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (1.12.1)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (0.3.3)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (3.14.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (1.12)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (1.1.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (0.10.0)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (2.4.1)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (3.3.0)\nRequirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (1.32.0)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (0.36.2)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (2.4.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow->text-gen) (3.7.4.3)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->text-gen) (3.3.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->text-gen) (1.8.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->text-gen) (1.24.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->text-gen) (0.4.2)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->text-gen) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->text-gen) (4.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->text-gen) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->text-gen) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->text-gen) (3.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->text-gen) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->text-gen) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow->text-gen) (3.4.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision->text-gen) (1.7.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision->text-gen) (0.18.2)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->torchvision->text-gen) (0.6)\nBuilding wheels for collected packages: parameter-sherpa, GPyOpt, GPy, paramz\n  Building wheel for parameter-sherpa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for parameter-sherpa: filename=parameter_sherpa-1.0.6-py2.py3-none-any.whl size=542118 sha256=4aadebc6cffe953c04d0b65f721f582cf9ecd4b73df794c9b2635cf7a764321d\n  Stored in directory: /root/.cache/pip/wheels/96/d9/cb/99569566e5e9b3ef0265ba4cbce3ff16f7692988833aa942f5\n  Building wheel for GPyOpt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPyOpt: filename=GPyOpt-1.2.6-py3-none-any.whl size=83621 sha256=7e14b6212755ea0bd541c853513211fb6758bc43693baa9e73126581fdcccec7\n  Stored in directory: /root/.cache/pip/wheels/e6/fa/d1/f9652b5af79f769a0ab74dbead7c7aea9a93c6bc74543fd3ec\n  Building wheel for GPy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPy: filename=GPy-1.9.9-cp37-cp37m-linux_x86_64.whl size=2626391 sha256=45f0c65d37a329af6e9d3e1635d7338d4f166ceb7eb7de95ed41864c8a903e3d\n  Stored in directory: /root/.cache/pip/wheels/e4/05/38/b84c6bec7ea9dc623cdbdb6203b55b3abe7a7020a992f2064c\n  Building wheel for paramz (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102550 sha256=cfe32090250000e2aba3c9be2c9629d06cf85e242e35a527b72d846ffd84c92d\n  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\nSuccessfully built parameter-sherpa GPyOpt GPy paramz\nInstalling collected packages: python-utils, paramz, keras-applications, seqeval, progressbar2, keras, GPy, seqtag-keras, pydload, GPyOpt, enum34, parameter-sherpa, deepsegment, text-gen\n  Attempting uninstall: keras\n    Found existing installation: Keras 2.4.3\n    Uninstalling Keras-2.4.3:\n      Successfully uninstalled Keras-2.4.3\nSuccessfully installed GPy-1.9.9 GPyOpt-1.2.6 deepsegment-2.3.1 enum34-1.1.10 keras-2.3.1 keras-applications-1.0.8 parameter-sherpa-1.0.6 paramz-0.9.5 progressbar2-3.53.1 pydload-1.0.9 python-utils-2.5.6 seqeval-0.0.3 seqtag-keras-1.0.6 text-gen-1.2.0\n",
          "name": "stdout"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00003-355d6317-54ba-42c0-b214-22b8e74882ab",
        "deepnote_cell_type": "code"
      },
      "source": "from text_gen import ten_textgen as ttg",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00004-d535e093-6fab-4bdf-a748-7006856fa7a5",
        "deepnote_cell_type": "code"
      },
      "source": "activation = 'softmax'\nlstmlayer = 128\npadding_method = 'pre'\n\nloss='categorical_crossentropy'\noptimizer='adam'\nmetrics='accuracy'\nepochs=500\nverbose = 0\npatience = 10\nbatch = 300\ndropout = 0.25",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00005-217ce58b-0eb1-4821-971a-a1234bdbcc3c",
        "deepnote_cell_type": "code"
      },
      "source": "pipeline = ttg.tentext(corpus)\nseq_text = pipeline.sequence(padding_method)\npipeline.configmodel(seq_text, lstmlayer, activation, dropout = 0.25)",
      "outputs": [
        {
          "output_type": "stream",
          "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 180, 64)           121408    \n_________________________________________________________________\ndropout (Dropout)            (None, 180, 64)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 128)               98816     \n_________________________________________________________________\ndense (Dense)                (None, 1897)              244713    \n=================================================================\nTotal params: 464,937\nTrainable params: 464,937\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fab5b5ddb90>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00006-3abf2374-1ad5-4c53-a20d-2ec0c3bd90c6",
        "deepnote_cell_type": "code"
      },
      "source": "model_history = pipeline.fit(loss = loss, optimizer = optimizer, batch = batch, metrics = metrics, epochs = epochs, verbose = 1, patience = patience)\n",
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/500\n79/79 [==============================] - 6s 27ms/step - loss: 6.7939 - accuracy: 0.0281\nEpoch 2/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.9380 - accuracy: 0.0406\nEpoch 3/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.8073 - accuracy: 0.0431\nEpoch 4/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.7286 - accuracy: 0.0459\nEpoch 5/500\n79/79 [==============================] - 2s 28ms/step - loss: 5.6378 - accuracy: 0.0424\nEpoch 6/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.5986 - accuracy: 0.0487\nEpoch 7/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.5275 - accuracy: 0.0496\nEpoch 8/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.4244 - accuracy: 0.0583\nEpoch 9/500\n79/79 [==============================] - 2s 27ms/step - loss: 5.3624 - accuracy: 0.0628\nEpoch 10/500\n79/79 [==============================] - 2s 27ms/step - loss: 5.2769 - accuracy: 0.0698\nEpoch 11/500\n79/79 [==============================] - 2s 27ms/step - loss: 5.2002 - accuracy: 0.0786\nEpoch 12/500\n79/79 [==============================] - 2s 26ms/step - loss: 5.1195 - accuracy: 0.0903\nEpoch 13/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.9934 - accuracy: 0.1046\nEpoch 14/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.8882 - accuracy: 0.1217\nEpoch 15/500\n79/79 [==============================] - 2s 28ms/step - loss: 4.7656 - accuracy: 0.1405\nEpoch 16/500\n79/79 [==============================] - 2s 27ms/step - loss: 4.6672 - accuracy: 0.1532\nEpoch 17/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.5849 - accuracy: 0.1604\nEpoch 18/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.4929 - accuracy: 0.1675\nEpoch 19/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.4127 - accuracy: 0.1785\nEpoch 20/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.3393 - accuracy: 0.1898\nEpoch 21/500\n79/79 [==============================] - 2s 27ms/step - loss: 4.2077 - accuracy: 0.2097\nEpoch 22/500\n79/79 [==============================] - 2s 25ms/step - loss: 4.1707 - accuracy: 0.2104\nEpoch 23/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.0969 - accuracy: 0.2186\nEpoch 24/500\n79/79 [==============================] - 2s 26ms/step - loss: 4.0122 - accuracy: 0.2305\nEpoch 25/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.9545 - accuracy: 0.2382\nEpoch 26/500\n79/79 [==============================] - 2s 27ms/step - loss: 3.8924 - accuracy: 0.2489\nEpoch 27/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.8011 - accuracy: 0.2619\nEpoch 28/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.7475 - accuracy: 0.2687\nEpoch 29/500\n79/79 [==============================] - 2s 25ms/step - loss: 3.6818 - accuracy: 0.2734\nEpoch 30/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.5997 - accuracy: 0.2880\nEpoch 31/500\n79/79 [==============================] - 2s 28ms/step - loss: 3.5549 - accuracy: 0.2951\nEpoch 32/500\n79/79 [==============================] - 2s 27ms/step - loss: 3.4840 - accuracy: 0.3083\nEpoch 33/500\n79/79 [==============================] - 2s 25ms/step - loss: 3.4429 - accuracy: 0.3150\nEpoch 34/500\n79/79 [==============================] - 2s 25ms/step - loss: 3.3783 - accuracy: 0.3304\nEpoch 35/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.3142 - accuracy: 0.3362\nEpoch 36/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.2807 - accuracy: 0.3417\nEpoch 37/500\n79/79 [==============================] - 2s 27ms/step - loss: 3.2036 - accuracy: 0.3548\nEpoch 38/500\n79/79 [==============================] - 2s 25ms/step - loss: 3.1959 - accuracy: 0.3559\nEpoch 39/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.1149 - accuracy: 0.3673\nEpoch 40/500\n79/79 [==============================] - 2s 26ms/step - loss: 3.0785 - accuracy: 0.3751\nEpoch 41/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.9957 - accuracy: 0.3913\nEpoch 42/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.9767 - accuracy: 0.3878\nEpoch 43/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.9247 - accuracy: 0.4009\nEpoch 44/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.8633 - accuracy: 0.4082\nEpoch 45/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.8493 - accuracy: 0.4126\nEpoch 46/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.7921 - accuracy: 0.4199\nEpoch 47/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.7792 - accuracy: 0.4240\nEpoch 48/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.7124 - accuracy: 0.4338\nEpoch 49/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.6957 - accuracy: 0.4389\nEpoch 50/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.6524 - accuracy: 0.4442\nEpoch 51/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.6334 - accuracy: 0.4473\nEpoch 52/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.5976 - accuracy: 0.4548\nEpoch 53/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.5675 - accuracy: 0.4604\nEpoch 54/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.5388 - accuracy: 0.4639\nEpoch 55/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.4981 - accuracy: 0.4708\nEpoch 56/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.4503 - accuracy: 0.4795\nEpoch 57/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.4466 - accuracy: 0.4773\nEpoch 58/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.3939 - accuracy: 0.4923\nEpoch 59/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.3872 - accuracy: 0.4932\nEpoch 60/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.3323 - accuracy: 0.4996\nEpoch 61/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.3319 - accuracy: 0.5017\nEpoch 62/500\n79/79 [==============================] - 2s 28ms/step - loss: 2.2858 - accuracy: 0.5114\nEpoch 63/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.2624 - accuracy: 0.5115\nEpoch 64/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.2586 - accuracy: 0.5144\nEpoch 65/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.2251 - accuracy: 0.5196\nEpoch 66/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.2088 - accuracy: 0.5219\nEpoch 67/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.2030 - accuracy: 0.5251\nEpoch 68/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.1619 - accuracy: 0.5284\nEpoch 69/500\n79/79 [==============================] - 2s 27ms/step - loss: 2.1417 - accuracy: 0.5357\nEpoch 70/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.1197 - accuracy: 0.5429\nEpoch 71/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.0902 - accuracy: 0.5452\nEpoch 72/500\n79/79 [==============================] - 2s 25ms/step - loss: 2.0778 - accuracy: 0.5428\nEpoch 73/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.0638 - accuracy: 0.5527\nEpoch 74/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.0344 - accuracy: 0.5559\nEpoch 75/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.0021 - accuracy: 0.5619\nEpoch 76/500\n79/79 [==============================] - 2s 26ms/step - loss: 2.0141 - accuracy: 0.5651\nEpoch 77/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.9661 - accuracy: 0.5726\nEpoch 78/500\n79/79 [==============================] - 2s 28ms/step - loss: 1.9388 - accuracy: 0.5758\nEpoch 79/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.9209 - accuracy: 0.5767\nEpoch 80/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.9263 - accuracy: 0.5741\nEpoch 81/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.8891 - accuracy: 0.5832\nEpoch 82/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "79/79 [==============================] - 2s 25ms/step - loss: 1.8891 - accuracy: 0.5812\nEpoch 83/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.8667 - accuracy: 0.5881\nEpoch 84/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.8565 - accuracy: 0.5854\nEpoch 85/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.8382 - accuracy: 0.5925 0s - los\nEpoch 86/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.8162 - accuracy: 0.5957\nEpoch 87/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.8174 - accuracy: 0.5935\nEpoch 88/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7755 - accuracy: 0.6003\nEpoch 89/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7837 - accuracy: 0.6004\nEpoch 90/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7586 - accuracy: 0.6049\nEpoch 91/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7424 - accuracy: 0.6099\nEpoch 92/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7564 - accuracy: 0.6101\nEpoch 93/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7178 - accuracy: 0.6174\nEpoch 94/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.7042 - accuracy: 0.6143\nEpoch 95/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.6918 - accuracy: 0.6216\nEpoch 96/500\n79/79 [==============================] - 2s 29ms/step - loss: 1.6691 - accuracy: 0.6252\nEpoch 97/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.6540 - accuracy: 0.6272\nEpoch 98/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.6538 - accuracy: 0.6242\nEpoch 99/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.6414 - accuracy: 0.6274\nEpoch 100/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.6525 - accuracy: 0.6252\nEpoch 101/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.6119 - accuracy: 0.6320\nEpoch 102/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5890 - accuracy: 0.6385\nEpoch 103/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5783 - accuracy: 0.6455\nEpoch 104/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5931 - accuracy: 0.6388\nEpoch 105/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.5736 - accuracy: 0.6443\nEpoch 106/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5427 - accuracy: 0.6503\nEpoch 107/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5614 - accuracy: 0.6439\nEpoch 108/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5334 - accuracy: 0.6505\nEpoch 109/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5348 - accuracy: 0.6505\nEpoch 110/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5169 - accuracy: 0.6525\nEpoch 111/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.5247 - accuracy: 0.6513\nEpoch 112/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.5179 - accuracy: 0.6520\nEpoch 113/500\n79/79 [==============================] - 2s 28ms/step - loss: 1.5067 - accuracy: 0.6520\nEpoch 114/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.4730 - accuracy: 0.6663\nEpoch 115/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.4479 - accuracy: 0.6669\nEpoch 116/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.4677 - accuracy: 0.6617\nEpoch 117/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.4611 - accuracy: 0.6626\nEpoch 118/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.4370 - accuracy: 0.6644\nEpoch 119/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.4280 - accuracy: 0.6745\nEpoch 120/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.4184 - accuracy: 0.6735\nEpoch 121/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.4207 - accuracy: 0.6721\nEpoch 122/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.4114 - accuracy: 0.6707\nEpoch 123/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.3998 - accuracy: 0.6775\nEpoch 124/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.3964 - accuracy: 0.6771\nEpoch 125/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.3827 - accuracy: 0.6807\nEpoch 126/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.3703 - accuracy: 0.6847\nEpoch 127/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.3759 - accuracy: 0.6835\nEpoch 128/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.3684 - accuracy: 0.6794\nEpoch 129/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.3588 - accuracy: 0.6809\nEpoch 130/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.3515 - accuracy: 0.6883\nEpoch 131/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.3347 - accuracy: 0.6875\nEpoch 132/500\n79/79 [==============================] - 2s 28ms/step - loss: 1.3148 - accuracy: 0.6923\nEpoch 133/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.3272 - accuracy: 0.6907\nEpoch 134/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.3176 - accuracy: 0.6923\nEpoch 135/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2935 - accuracy: 0.6989\nEpoch 136/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2902 - accuracy: 0.6911\nEpoch 137/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2883 - accuracy: 0.6998\nEpoch 138/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.3013 - accuracy: 0.6928\nEpoch 139/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.2667 - accuracy: 0.6984\nEpoch 140/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2615 - accuracy: 0.7014\nEpoch 141/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2655 - accuracy: 0.7062\nEpoch 142/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2542 - accuracy: 0.7029\nEpoch 143/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2410 - accuracy: 0.7081\nEpoch 144/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.2504 - accuracy: 0.7032\nEpoch 145/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2559 - accuracy: 0.7040\nEpoch 146/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2407 - accuracy: 0.7052\nEpoch 147/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2227 - accuracy: 0.7105\nEpoch 148/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.2124 - accuracy: 0.7115\nEpoch 149/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.1971 - accuracy: 0.7154\nEpoch 150/500\n79/79 [==============================] - 2s 28ms/step - loss: 1.2129 - accuracy: 0.7121\nEpoch 151/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2407 - accuracy: 0.7069\nEpoch 152/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2208 - accuracy: 0.7118\nEpoch 153/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.2092 - accuracy: 0.7121\nEpoch 154/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.1900 - accuracy: 0.7156\nEpoch 155/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.1868 - accuracy: 0.7189\nEpoch 156/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1838 - accuracy: 0.7194\nEpoch 157/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1822 - accuracy: 0.7197\nEpoch 158/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1638 - accuracy: 0.7231\nEpoch 159/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1615 - accuracy: 0.7247\nEpoch 160/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.1478 - accuracy: 0.7277\nEpoch 161/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1517 - accuracy: 0.7230\nEpoch 162/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "79/79 [==============================] - 2s 25ms/step - loss: 1.1555 - accuracy: 0.7228\nEpoch 163/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1463 - accuracy: 0.7225\nEpoch 164/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1313 - accuracy: 0.7317\nEpoch 165/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.1305 - accuracy: 0.7336\nEpoch 166/500\n79/79 [==============================] - 2s 29ms/step - loss: 1.1354 - accuracy: 0.7262\nEpoch 167/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.1134 - accuracy: 0.7339\nEpoch 168/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.1121 - accuracy: 0.7308\nEpoch 169/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0935 - accuracy: 0.7325\nEpoch 170/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0947 - accuracy: 0.7370\nEpoch 171/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.1000 - accuracy: 0.7337\nEpoch 172/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0927 - accuracy: 0.7320\nEpoch 173/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0787 - accuracy: 0.7384\nEpoch 174/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0833 - accuracy: 0.7365\nEpoch 175/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0884 - accuracy: 0.7358\nEpoch 176/500\n79/79 [==============================] - 2s 27ms/step - loss: 1.0631 - accuracy: 0.7407\nEpoch 177/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0662 - accuracy: 0.7438\nEpoch 178/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0535 - accuracy: 0.7435\nEpoch 179/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0578 - accuracy: 0.7421\nEpoch 180/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0609 - accuracy: 0.7393\nEpoch 181/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0681 - accuracy: 0.7416\nEpoch 182/500\n79/79 [==============================] - 2s 29ms/step - loss: 1.0410 - accuracy: 0.7485\nEpoch 183/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0311 - accuracy: 0.7486\nEpoch 184/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0274 - accuracy: 0.7492\nEpoch 185/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0319 - accuracy: 0.7453\nEpoch 186/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0372 - accuracy: 0.7488\nEpoch 187/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0139 - accuracy: 0.7513\nEpoch 188/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0157 - accuracy: 0.7482\nEpoch 189/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0094 - accuracy: 0.7524\nEpoch 190/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0167 - accuracy: 0.7510\nEpoch 191/500\n79/79 [==============================] - 2s 25ms/step - loss: 1.0158 - accuracy: 0.7537\nEpoch 192/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0080 - accuracy: 0.7502\nEpoch 193/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.9917 - accuracy: 0.7590\nEpoch 194/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0004 - accuracy: 0.7531\nEpoch 195/500\n79/79 [==============================] - 2s 26ms/step - loss: 1.0010 - accuracy: 0.7543\nEpoch 196/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9884 - accuracy: 0.7551\nEpoch 197/500\n79/79 [==============================] - 2s 30ms/step - loss: 0.9957 - accuracy: 0.7543\nEpoch 198/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9932 - accuracy: 0.7548\nEpoch 199/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9821 - accuracy: 0.7553\nEpoch 200/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9811 - accuracy: 0.7570\nEpoch 201/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.9638 - accuracy: 0.7615\nEpoch 202/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9864 - accuracy: 0.7536\nEpoch 203/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.9544 - accuracy: 0.7611\nEpoch 204/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9685 - accuracy: 0.7602\nEpoch 205/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.9739 - accuracy: 0.7587\nEpoch 206/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.9639 - accuracy: 0.7601\nEpoch 207/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9577 - accuracy: 0.7641\nEpoch 208/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.9709 - accuracy: 0.7599\nEpoch 209/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9529 - accuracy: 0.7611\nEpoch 210/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9336 - accuracy: 0.7696\nEpoch 211/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9407 - accuracy: 0.7641\nEpoch 212/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9379 - accuracy: 0.7672\nEpoch 213/500\n79/79 [==============================] - 2s 29ms/step - loss: 0.9290 - accuracy: 0.7672\nEpoch 214/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9348 - accuracy: 0.7668\nEpoch 215/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9231 - accuracy: 0.7679\nEpoch 216/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9186 - accuracy: 0.7722\nEpoch 217/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.9344 - accuracy: 0.7699\nEpoch 218/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9251 - accuracy: 0.7697\nEpoch 219/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.9149 - accuracy: 0.7704\nEpoch 220/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9257 - accuracy: 0.7691\nEpoch 221/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9124 - accuracy: 0.7671\nEpoch 222/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9086 - accuracy: 0.7722\nEpoch 223/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9090 - accuracy: 0.7698\nEpoch 224/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8955 - accuracy: 0.7753\nEpoch 225/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.9045 - accuracy: 0.7745\nEpoch 226/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8920 - accuracy: 0.7772\nEpoch 227/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8885 - accuracy: 0.7737\nEpoch 228/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8836 - accuracy: 0.7778\nEpoch 229/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.8951 - accuracy: 0.7744\nEpoch 230/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8682 - accuracy: 0.7791\nEpoch 231/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8716 - accuracy: 0.7805\nEpoch 232/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8675 - accuracy: 0.7832\nEpoch 233/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8712 - accuracy: 0.7798\nEpoch 234/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8693 - accuracy: 0.7791\nEpoch 235/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8716 - accuracy: 0.7805\nEpoch 236/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8640 - accuracy: 0.7800\nEpoch 237/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8568 - accuracy: 0.7800\nEpoch 238/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8632 - accuracy: 0.7820\nEpoch 239/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8708 - accuracy: 0.7812\nEpoch 240/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8593 - accuracy: 0.7837\nEpoch 241/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8422 - accuracy: 0.7858\nEpoch 242/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "79/79 [==============================] - 2s 25ms/step - loss: 0.8552 - accuracy: 0.7843\nEpoch 243/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8461 - accuracy: 0.7855\nEpoch 244/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.8427 - accuracy: 0.7831\nEpoch 245/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8449 - accuracy: 0.7868\nEpoch 246/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8284 - accuracy: 0.7908\nEpoch 247/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8343 - accuracy: 0.7870\nEpoch 248/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8252 - accuracy: 0.7891\nEpoch 249/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8335 - accuracy: 0.7886\nEpoch 250/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8240 - accuracy: 0.7882\nEpoch 251/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8212 - accuracy: 0.7938\nEpoch 252/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8261 - accuracy: 0.7892\nEpoch 253/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8449 - accuracy: 0.7850\nEpoch 254/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8310 - accuracy: 0.7869\nEpoch 255/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8135 - accuracy: 0.7936\nEpoch 256/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.8223 - accuracy: 0.7884\nEpoch 257/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8193 - accuracy: 0.7908\nEpoch 258/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8220 - accuracy: 0.7867\nEpoch 259/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8084 - accuracy: 0.7912\nEpoch 260/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.8072 - accuracy: 0.7921\nEpoch 261/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7937 - accuracy: 0.7932\nEpoch 262/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7976 - accuracy: 0.7927\nEpoch 263/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.8080 - accuracy: 0.7913\nEpoch 264/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8017 - accuracy: 0.7910\nEpoch 265/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8003 - accuracy: 0.7919\nEpoch 266/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7976 - accuracy: 0.7956\nEpoch 267/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7772 - accuracy: 0.7995\nEpoch 268/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.8009 - accuracy: 0.7957\nEpoch 269/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7984 - accuracy: 0.7938\nEpoch 270/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7756 - accuracy: 0.7988\nEpoch 271/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7934 - accuracy: 0.7969\nEpoch 272/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7767 - accuracy: 0.8012\nEpoch 273/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7815 - accuracy: 0.7988\nEpoch 274/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7922 - accuracy: 0.7954\nEpoch 275/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7704 - accuracy: 0.8037\nEpoch 276/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7861 - accuracy: 0.7935\nEpoch 277/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7613 - accuracy: 0.8012\nEpoch 278/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7863 - accuracy: 0.7967\nEpoch 279/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7765 - accuracy: 0.8001\nEpoch 280/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7649 - accuracy: 0.7995\nEpoch 281/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7758 - accuracy: 0.8000\nEpoch 282/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7575 - accuracy: 0.8036\nEpoch 283/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7568 - accuracy: 0.8023\nEpoch 284/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7562 - accuracy: 0.8030\nEpoch 285/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7686 - accuracy: 0.8035\nEpoch 286/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7624 - accuracy: 0.8034\nEpoch 287/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7655 - accuracy: 0.8003\nEpoch 288/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7558 - accuracy: 0.8011\nEpoch 289/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7551 - accuracy: 0.8042\nEpoch 290/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7397 - accuracy: 0.8071\nEpoch 291/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.7472 - accuracy: 0.8037\nEpoch 292/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7487 - accuracy: 0.8020\nEpoch 293/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7472 - accuracy: 0.8079\nEpoch 294/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7580 - accuracy: 0.8047\nEpoch 295/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7389 - accuracy: 0.8041\nEpoch 296/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7403 - accuracy: 0.8069\nEpoch 297/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7482 - accuracy: 0.8022\nEpoch 298/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7436 - accuracy: 0.8066\nEpoch 299/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7298 - accuracy: 0.8081\nEpoch 300/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7400 - accuracy: 0.8026\nEpoch 301/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7408 - accuracy: 0.8095\nEpoch 302/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7310 - accuracy: 0.8091\nEpoch 303/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7297 - accuracy: 0.8126\nEpoch 304/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7417 - accuracy: 0.8035\nEpoch 305/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7187 - accuracy: 0.8094\nEpoch 306/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7314 - accuracy: 0.8057\nEpoch 307/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.7326 - accuracy: 0.8084\nEpoch 308/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6970 - accuracy: 0.8183\nEpoch 309/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7144 - accuracy: 0.8121\nEpoch 310/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7249 - accuracy: 0.8094\nEpoch 311/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7181 - accuracy: 0.8115\nEpoch 312/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7223 - accuracy: 0.8099\nEpoch 313/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7143 - accuracy: 0.8121\nEpoch 314/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7064 - accuracy: 0.8141\nEpoch 315/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.7102 - accuracy: 0.8114\nEpoch 316/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7099 - accuracy: 0.8119\nEpoch 317/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7049 - accuracy: 0.8155\nEpoch 318/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7087 - accuracy: 0.8126\nEpoch 319/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6987 - accuracy: 0.8133\nEpoch 320/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.7044 - accuracy: 0.8156\nEpoch 321/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6957 - accuracy: 0.8154\nEpoch 322/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "79/79 [==============================] - 2s 28ms/step - loss: 0.7036 - accuracy: 0.8081\nEpoch 323/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.7089 - accuracy: 0.8121\nEpoch 324/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6880 - accuracy: 0.8144\nEpoch 325/500\n79/79 [==============================] - 2s 30ms/step - loss: 0.6989 - accuracy: 0.8149\nEpoch 326/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6948 - accuracy: 0.8187\nEpoch 327/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.7017 - accuracy: 0.8159\nEpoch 328/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6932 - accuracy: 0.8162\nEpoch 329/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6787 - accuracy: 0.8173\nEpoch 330/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6866 - accuracy: 0.8174\nEpoch 331/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6938 - accuracy: 0.8174\nEpoch 332/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6922 - accuracy: 0.8210\nEpoch 333/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6827 - accuracy: 0.8171\nEpoch 334/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6899 - accuracy: 0.8156\nEpoch 335/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6837 - accuracy: 0.8188\nEpoch 336/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6848 - accuracy: 0.8181\nEpoch 337/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6811 - accuracy: 0.8151\nEpoch 338/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6810 - accuracy: 0.8199\nEpoch 339/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6769 - accuracy: 0.8174\nEpoch 340/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6760 - accuracy: 0.8204\nEpoch 341/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.6720 - accuracy: 0.8239\nEpoch 342/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6676 - accuracy: 0.8212\nEpoch 343/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6719 - accuracy: 0.8186\nEpoch 344/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6642 - accuracy: 0.8208\nEpoch 345/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6813 - accuracy: 0.8177\nEpoch 346/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6711 - accuracy: 0.8201\nEpoch 347/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6688 - accuracy: 0.8207\nEpoch 348/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6618 - accuracy: 0.8205\nEpoch 349/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6817 - accuracy: 0.8181\nEpoch 350/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6687 - accuracy: 0.8199\nEpoch 351/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6812 - accuracy: 0.8161\nEpoch 352/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6736 - accuracy: 0.8209\nEpoch 353/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.6594 - accuracy: 0.8240\nEpoch 354/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6729 - accuracy: 0.8201\nEpoch 355/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6500 - accuracy: 0.8236\nEpoch 356/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6534 - accuracy: 0.8223\nEpoch 357/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6650 - accuracy: 0.8212\nEpoch 358/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6492 - accuracy: 0.8277\nEpoch 359/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6458 - accuracy: 0.8254\nEpoch 360/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6465 - accuracy: 0.8256\nEpoch 361/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6598 - accuracy: 0.8228\nEpoch 362/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6573 - accuracy: 0.8244\nEpoch 363/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6661 - accuracy: 0.8218\nEpoch 364/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6610 - accuracy: 0.8226\nEpoch 365/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6368 - accuracy: 0.8296\nEpoch 366/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6361 - accuracy: 0.8285\nEpoch 367/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6477 - accuracy: 0.8289\nEpoch 368/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6460 - accuracy: 0.8239\nEpoch 369/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.6406 - accuracy: 0.8268\nEpoch 370/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6353 - accuracy: 0.8286\nEpoch 371/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6428 - accuracy: 0.8235\nEpoch 372/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6528 - accuracy: 0.8230\nEpoch 373/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6366 - accuracy: 0.8292\nEpoch 374/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6384 - accuracy: 0.8254\nEpoch 375/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6286 - accuracy: 0.8280\nEpoch 376/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6380 - accuracy: 0.8286\nEpoch 377/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6353 - accuracy: 0.8270\nEpoch 378/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6371 - accuracy: 0.8272\nEpoch 379/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6251 - accuracy: 0.8314\nEpoch 380/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6402 - accuracy: 0.8242\nEpoch 381/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6311 - accuracy: 0.8288\nEpoch 382/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6406 - accuracy: 0.8257\nEpoch 383/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6456 - accuracy: 0.8278\nEpoch 384/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6370 - accuracy: 0.8259\nEpoch 385/500\n79/79 [==============================] - 2s 28ms/step - loss: 0.6304 - accuracy: 0.8285\nEpoch 386/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6316 - accuracy: 0.8288\nEpoch 387/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6287 - accuracy: 0.8284\nEpoch 388/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6293 - accuracy: 0.8316\nEpoch 389/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6230 - accuracy: 0.8300\nEpoch 390/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6250 - accuracy: 0.8281\nEpoch 391/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6281 - accuracy: 0.8305\nEpoch 392/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6217 - accuracy: 0.8301\nEpoch 393/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6155 - accuracy: 0.8325\nEpoch 394/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6244 - accuracy: 0.8261\nEpoch 395/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6099 - accuracy: 0.8337\nEpoch 396/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6271 - accuracy: 0.8295\nEpoch 397/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6346 - accuracy: 0.8280\nEpoch 398/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6148 - accuracy: 0.8328\nEpoch 399/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6455 - accuracy: 0.8244\nEpoch 400/500\n79/79 [==============================] - 2s 30ms/step - loss: 0.6150 - accuracy: 0.8331\nEpoch 401/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6072 - accuracy: 0.8354\nEpoch 402/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "79/79 [==============================] - 2s 26ms/step - loss: 0.6306 - accuracy: 0.8289\nEpoch 403/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6176 - accuracy: 0.8311\nEpoch 404/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6211 - accuracy: 0.8311\nEpoch 405/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6205 - accuracy: 0.8294\nEpoch 406/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6096 - accuracy: 0.8367\nEpoch 407/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6201 - accuracy: 0.8291\nEpoch 408/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6095 - accuracy: 0.8299\nEpoch 409/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6012 - accuracy: 0.8356\nEpoch 410/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6041 - accuracy: 0.8339\nEpoch 411/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.6138 - accuracy: 0.8325\nEpoch 412/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6043 - accuracy: 0.8337\nEpoch 413/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5991 - accuracy: 0.8374\nEpoch 414/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6063 - accuracy: 0.8318\nEpoch 415/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5936 - accuracy: 0.8352\nEpoch 416/500\n79/79 [==============================] - 2s 30ms/step - loss: 0.6021 - accuracy: 0.8346\nEpoch 417/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5938 - accuracy: 0.8362\nEpoch 418/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6014 - accuracy: 0.8344\nEpoch 419/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5998 - accuracy: 0.8375\nEpoch 420/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5978 - accuracy: 0.8349\nEpoch 421/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6067 - accuracy: 0.8338\nEpoch 422/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5928 - accuracy: 0.8386\nEpoch 423/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5937 - accuracy: 0.8386\nEpoch 424/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6151 - accuracy: 0.8313\nEpoch 425/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6018 - accuracy: 0.8340\nEpoch 426/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6027 - accuracy: 0.8318\nEpoch 427/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5930 - accuracy: 0.8363\nEpoch 428/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5914 - accuracy: 0.8345\nEpoch 429/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5967 - accuracy: 0.8362\nEpoch 430/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5928 - accuracy: 0.8351\nEpoch 431/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.6750 - accuracy: 0.8144\nEpoch 432/500\n79/79 [==============================] - 2s 30ms/step - loss: 0.6012 - accuracy: 0.8355\nEpoch 433/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5896 - accuracy: 0.8377\nEpoch 434/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.6002 - accuracy: 0.8334\nEpoch 435/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5874 - accuracy: 0.8344\nEpoch 436/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5801 - accuracy: 0.8401\nEpoch 437/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5831 - accuracy: 0.8351\nEpoch 438/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5813 - accuracy: 0.8398\nEpoch 439/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5942 - accuracy: 0.8334\nEpoch 440/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5919 - accuracy: 0.8347\nEpoch 441/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5857 - accuracy: 0.8369\nEpoch 442/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5913 - accuracy: 0.8363\nEpoch 443/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5910 - accuracy: 0.8372\nEpoch 444/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5909 - accuracy: 0.8349\nEpoch 445/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5805 - accuracy: 0.8365\nEpoch 446/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5806 - accuracy: 0.8386\nEpoch 447/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5836 - accuracy: 0.8366\nEpoch 448/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5905 - accuracy: 0.8347\nEpoch 449/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5777 - accuracy: 0.8400\nEpoch 450/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5715 - accuracy: 0.8437\nEpoch 451/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5763 - accuracy: 0.8374\nEpoch 452/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5759 - accuracy: 0.8434\nEpoch 453/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5662 - accuracy: 0.8447\nEpoch 454/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5702 - accuracy: 0.8401\nEpoch 455/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5714 - accuracy: 0.8414\nEpoch 456/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5708 - accuracy: 0.8416\nEpoch 457/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5680 - accuracy: 0.8446\nEpoch 458/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5881 - accuracy: 0.8364\nEpoch 459/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5666 - accuracy: 0.8435\nEpoch 460/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5754 - accuracy: 0.8394\nEpoch 461/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5747 - accuracy: 0.8395\nEpoch 462/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5712 - accuracy: 0.8391\nEpoch 463/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5685 - accuracy: 0.8433\nEpoch 464/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5698 - accuracy: 0.8403\nEpoch 465/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5591 - accuracy: 0.8441\nEpoch 466/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5770 - accuracy: 0.8370\nEpoch 467/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5705 - accuracy: 0.8399\nEpoch 468/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5780 - accuracy: 0.8381\nEpoch 469/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5589 - accuracy: 0.8437\nEpoch 470/500\n79/79 [==============================] - 2s 27ms/step - loss: 0.5633 - accuracy: 0.8432\nEpoch 471/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5804 - accuracy: 0.8344\nEpoch 472/500\n79/79 [==============================] - 2s 26ms/step - loss: 0.5777 - accuracy: 0.8374\nEpoch 473/500\n79/79 [==============================] - 2s 25ms/step - loss: 0.5715 - accuracy: 0.8393\n",
          "name": "stdout"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00007-f7504b9a-de19-4805-8cd1-0f72dab77c0e",
        "deepnote_cell_type": "code"
      },
      "source": "!pip install -U deepsegment",
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: deepsegment in /opt/conda/lib/python3.7/site-packages (2.3.1)\nRequirement already satisfied: progressbar2 in /opt/conda/lib/python3.7/site-packages (from deepsegment) (3.53.1)\nRequirement already satisfied: seqtag-keras in /opt/conda/lib/python3.7/site-packages (from deepsegment) (1.0.6)\nRequirement already satisfied: pydload in /opt/conda/lib/python3.7/site-packages (from deepsegment) (1.0.9)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from progressbar2->deepsegment) (1.15.0)\nRequirement already satisfied: python-utils>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from progressbar2->deepsegment) (2.5.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pydload->deepsegment) (2.25.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pydload->deepsegment) (1.26.2)\nRequirement already satisfied: Keras<=2.3.1 in /opt/conda/lib/python3.7/site-packages (from seqtag-keras->deepsegment) (2.3.1)\nRequirement already satisfied: seqeval==0.0.3 in /opt/conda/lib/python3.7/site-packages (from seqtag-keras->deepsegment) (0.0.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from seqtag-keras->deepsegment) (0.24.1)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==0.0.3->seqtag-keras->deepsegment) (1.19.5)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from Keras<=2.3.1->seqtag-keras->deepsegment) (1.1.2)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras<=2.3.1->seqtag-keras->deepsegment) (2.10.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras<=2.3.1->seqtag-keras->deepsegment) (1.5.4)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras<=2.3.1->seqtag-keras->deepsegment) (5.3.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from Keras<=2.3.1->seqtag-keras->deepsegment) (1.0.8)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->seqtag-keras->deepsegment) (1.0.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->seqtag-keras->deepsegment) (2.1.0)\n",
          "name": "stdout"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00008-de75a178-c5dd-4769-83f0-080a64fe4d61",
        "deepnote_cell_type": "code"
      },
      "source": "from deepsegment import DeepSegment\n# The default language is 'en'\nsegmenter = DeepSegment('en')\nsegmenter.segment(text)",
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0a3c5570ea2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepsegment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# The default language is 'en'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msegmenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepSegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/deepsegment/deepsegment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang_code, checkpoint_path, params_path, utils_path, tf_serving, checkpoint_name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf_serving\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mDeepSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseqtag_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'CRF'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mDeepSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseqtag_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1073\u001b[0m                         \u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m                             \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                         \u001b[0;31m# If the node does not have all inbound layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# and building the layer if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 raise ValueError('Layer ' + self.name + ' was called with '\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m    697\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TensorLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00009-dfe8cecd-03b2-4825-92db-e44d1800c8ad",
        "deepnote_cell_type": "code"
      },
      "source": "text = pipeline.predict(\"he yo\", word_length = 100)",
      "outputs": [
        {
          "output_type": "stream",
          "text": "1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\nhe yo creo que ella siente que ya estoy atrapado ¿estás hablando conmigo time baby days like her all you girl see what i see i won't see you again you're on one two one two three oh yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah\n",
          "name": "stdout"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00010-e6d7109e-ff2f-4f46-aa82-a29b8cf947e4",
        "deepnote_cell_type": "code"
      },
      "source": "!pip install tensorflow-serving-api==1.12.0",
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting tensorflow-serving-api==1.12.0\n  Downloading tensorflow_serving_api-1.12.0-py2.py3-none-any.whl (39 kB)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-serving-api==1.12.0) (3.14.0)\nRequirement already satisfied: grpcio>=1.0<2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-serving-api==1.12.0) (1.32.0)\nCollecting tensorflow<2,>=1.2.0\n  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n\u001b[K     |████████████████████████████████| 110.5 MB 1.6 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.7/site-packages (from grpcio>=1.0<2->tensorflow-serving-api==1.12.0) (1.15.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (0.36.2)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nCollecting numpy<1.19.0,>=1.16.0\n  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n\u001b[K     |████████████████████████████████| 20.1 MB 44.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (1.1.2)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (1.1.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (0.2.0)\nCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n\u001b[K     |████████████████████████████████| 503 kB 54.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: h5py<=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (2.10.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (0.10.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (3.3.0)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (1.0.8)\nCollecting tensorboard<1.16.0,>=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 50.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (1.12.1)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (49.6.0.post20201009)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (1.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (3.3.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (3.3.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.2.0->tensorflow-serving-api==1.12.0) (3.4.0)\nBuilding wheels for collected packages: gast\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7538 sha256=527c8c58a12e8cbc4efb9e01e6bd3499d6691ef75c4e20812df87b787cc579aa\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built gast\nInstalling collected packages: numpy, tensorflow-estimator, tensorboard, gast, astor, tensorflow, tensorflow-serving-api\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.5\n    Uninstalling numpy-1.19.5:\n      Successfully uninstalled numpy-1.19.5\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.4.0\n    Uninstalling tensorflow-estimator-2.4.0:\n      Successfully uninstalled tensorflow-estimator-2.4.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.4.1\n    Uninstalling tensorboard-2.4.1:\n      Successfully uninstalled tensorboard-2.4.1\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.4.1\n    Uninstalling tensorflow-2.4.1:\n      Successfully uninstalled tensorflow-2.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nucx-py 0.16.0 requires pynvml, which is not installed.\ntensorflow-probability 0.12.1 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\ntensorflow-cloud 0.1.13 requires tensorboard>=2.3.0, but you have tensorboard 1.15.0 which is incompatible.\npytorch-lightning 1.2.0 requires tensorboard>=2.2.0, but you have tensorboard 1.15.0 which is incompatible.\nosmnx 1.0.1 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\nbokeh 2.2.3 requires tornado>=5.1, but you have tornado 5.0.2 which is incompatible.\nautogluon-core 0.1.0b20210219 requires numpy==1.19.5, but you have numpy 1.18.5 which is incompatible.\u001b[0m\nSuccessfully installed astor-0.8.1 gast-0.2.2 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1 tensorflow-serving-api-1.12.0\n",
          "name": "stdout"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cell_id": "00011-69394d4b-61cc-4d99-be70-972453fee840",
        "deepnote_cell_type": "code"
      },
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c4d6afe8-54f4-47df-9ef1-b74e3582b118' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "deepnote_notebook_id": "1c9bdc38-d95f-4648-903d-6b103196bfcf",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}